{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ZV6H98a9EzEC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "rpZ0qLpD889d",
        "outputId": "0f248508-31dd-45c1-f9e6-d43e6c5aa3be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensorflow' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b9ca7990e127>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tensorflow' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError: # If TPU not found\n",
        "  tpu = None"
      ],
      "metadata": {
        "id": "b8zKQar_En6R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select appropriate distribution strategy\n",
        "if tpu:\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # Default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU instead')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "jrPa-6OaE51j",
        "outputId": "f6cb7625-f018-4856-8780-4b9dd7589735"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use the non-experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'worker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6c17d606e182>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running on TPU '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'worker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Default strategy that works on CPU and single GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'worker'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'worker' in tpu.cluster_spec().as_dict():\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "else:\n",
        "  print('Running on TPU without a worker key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEyiZOSnGCJ1",
        "outputId": "e6da1097-3e26-4404-99f0-a5864c443d44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU without a worker key\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "9CW6plvBE_N3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(x)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(conv)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    return conv\n"
      ],
      "metadata": {
        "id": "JpoToQ-hEvz2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "#convolutional block\n",
        "def conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(x)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(conv)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    return conv\n",
        "\n",
        "\n",
        "#residual convolutional block\n",
        "def res_conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv1 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        conv1 = layers.BatchNormalization(axis=3)(conv1)\n",
        "    conv1 = layers.Activation('relu')(conv1)\n",
        "    conv2 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(conv1)\n",
        "    if batchnorm is True:\n",
        "        conv2 = layers.BatchNormalization(axis=3)(conv2)\n",
        "        conv2 = layers.Activation(\"relu\")(conv2)\n",
        "    if dropout > 0:\n",
        "        conv2 = layers.Dropout(dropout)(conv2)\n",
        "\n",
        "    #skip connection\n",
        "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "    shortcut = layers.Activation(\"relu\")(shortcut)\n",
        "    respath = layers.add([shortcut, conv2])\n",
        "    return respath\n",
        "\n",
        "\n",
        "#gating signal for attention unit\n",
        "def gatingsignal(input, out_size, batchnorm=False):\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batchnorm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "#attention unit/block based on soft attention\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), kernel_initializer='he_normal', padding='same')(x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), kernel_initializer='he_normal', padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3), strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]), kernel_initializer='he_normal', padding='same')(phi_g)\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), kernel_initializer='he_normal', padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
        "    upsample_psi = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': shape_x[3]})(upsample_psi)\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), kernel_initializer='he_normal', padding='same')(y)\n",
        "    attenblock = layers.BatchNormalization()(result)\n",
        "    return attenblock\n",
        "\n",
        "#Simple U-NET\n",
        "def unetmodel(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, dn_4], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, dn_3], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, dn_2], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, dn_1], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "#Attention U-NET\n",
        "def attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "#Res-UNET\n",
        "def residualunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_conv1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    dn_pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv1)\n",
        "\n",
        "    dn_conv2 = res_conv_block(dn_pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    dn_pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv2)\n",
        "\n",
        "    dn_conv3 = res_conv_block(dn_pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    dn_pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv3)\n",
        "\n",
        "    dn_conv4 = res_conv_block(dn_pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    dn_pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv4)\n",
        "\n",
        "    dn_conv5 = res_conv_block(dn_pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # upsampling layers\n",
        "    up_conv6 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_conv5)\n",
        "    up_conv6 = layers.concatenate([up_conv6, dn_conv4], axis=3)\n",
        "    up_conv6 = res_conv_block(up_conv6, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_conv7 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv6)\n",
        "    up_conv7 = layers.concatenate([up_conv7, dn_conv3], axis=3)\n",
        "    up_conv7 = res_conv_block(up_conv7, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_conv8 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv7)\n",
        "    up_conv8 = layers.concatenate([up_conv8, dn_conv2], axis=3)\n",
        "    up_conv8 = res_conv_block(up_conv8, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_conv9 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv8)\n",
        "    up_conv9 = layers.concatenate([up_conv9, dn_conv1], axis=3)\n",
        "    up_conv9 = res_conv_block(up_conv9, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv9)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "#Residual-Attention UNET (RA-UNET)\n",
        "def residual_attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = res_conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = res_conv_block(pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = res_conv_block(pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = res_conv_block(pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = res_conv_block(pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = res_conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = res_conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = res_conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = res_conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "Wgm7O8h4x9Wn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "\n",
        "\n",
        "def IoU_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def IoU_loss(y_true, y_pred):\n",
        "    return -IoU_coef(y_true, y_pred)\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    return acc\n",
        "\n",
        "def IoU(y_true, y_pred, labels = [0, 1]):\n",
        "   IoU = []\n",
        "   for label in labels:\n",
        "      jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='weighted')\n",
        "      IoU.append(jaccard)\n",
        "   return np.mean(IoU)"
      ],
      "metadata": {
        "id": "Ciaubc2AyBf_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from patchify import patchify\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "#CLAHE\n",
        "def clahe_equalized(imgs):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    imgs_equalized = clahe.apply(imgs)\n",
        "    return imgs_equalized\n",
        "\n",
        "path1 = 'drive/My Drive/training/diabetic_retinopathy_input' #training images directory\n",
        "path2 = 'drive/My Drive/training//diabetic_retinopathy_fovmask' #training masks directory\n",
        "\n",
        "image_dataset = []\n",
        "mask_dataset = []\n",
        "\n",
        "patch_size = 512\n",
        "\n",
        "images = sorted(os.listdir(path1))\n",
        "for i, image_name in enumerate(images):\n",
        "   if image_name.endswith(\".JPG\"):\n",
        "       image = skimage.io.imread(os.path.join(path1, image_name))  #Read image\n",
        "       image = image[:,:,1] #selecting green channel\n",
        "       image = clahe_equalized(image) #applying CLAHE\n",
        "       SIZE_X = (image.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "       SIZE_Y = (image.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "       image = Image.fromarray(image)\n",
        "       image = image.resize((SIZE_X, SIZE_Y)) #resize image\n",
        "       image = np.array(image)\n",
        "       patches_img = patchify(image, (patch_size, patch_size), step=patch_size)  #create patches(patch_sizexpatch_sizex1)\n",
        "\n",
        "       for i in range(patches_img.shape[0]):\n",
        "           for j in range(patches_img.shape[1]):\n",
        "               single_patch_img = patches_img[i,j,:,:]\n",
        "               single_patch_img = (single_patch_img.astype('float32')) / 255.\n",
        "               image_dataset.append(single_patch_img)\n",
        "\n",
        "masks = sorted(os.listdir(path2))\n",
        "for i, mask_name in enumerate(masks):\n",
        "    if mask_name.endswith(\".tif\"):\n",
        "        mask = skimage.io.imread(os.path.join(path2, mask_name))   #Read masks\n",
        "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)  # Convert mask to grayscale\n",
        "        SIZE_X = (mask_gray.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "        SIZE_Y = (mask_gray.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "\n",
        "        for y in range(0, SIZE_Y, patch_size):\n",
        "            for x in range(0, SIZE_X, patch_size):\n",
        "                patch = mask_gray[y:y+patch_size, x:x+patch_size]\n",
        "                patch = (patch.astype('float32')) / 255.\n",
        "                mask_dataset.append(patch)\n",
        "\n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "image_dataset = np.expand_dims(image_dataset,axis=-1)\n",
        "mask_dataset =  np.expand_dims(mask_dataset,axis=-1)\n",
        "\n",
        "# Importing models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "IMG_HEIGHT = patch_size\n",
        "IMG_WIDTH = patch_size\n",
        "IMG_CHANNELS = 1\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = unetmodel(input_shape)\n",
        "model.compile(optimizer = Adam(learning_rate = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "# Splitting data into 70-30 ratio to validate training performance\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size=0.3, random_state=0)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    verbose=1,\n",
        "                    batch_size = 16,\n",
        "                    validation_data=(x_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=150)\n",
        "\n",
        "# Training-validation loss curve\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Training-validation accuracy curve\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'y', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Training-validation IoU curve\n",
        "iou_coef = history.history['IoU_coef']\n",
        "val_iou_coef = history.history['val_IoU_coef']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, iou_coef, 'r', label='Training IoU')\n",
        "plt.plot(epochs, val_iou_coef, 'y', label='Validation IoU')\n",
        "plt.title('Training and validation IoU coefficients')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jj8-cRjnyQtg",
        "outputId": "f3738424-20f8-4ac9-bb12-310e7cc8ac96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 512, 512, 16)         160       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 512, 512, 16)         64        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 512, 512, 16)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 512, 512, 16)         0         ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 512, 512, 16)         2320      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 512, 512, 16)         64        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 512, 512, 16)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 256, 256, 16)         0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 256, 256, 32)         4640      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 256, 256, 32)         128       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 256, 256, 32)         0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256, 256, 32)         0         ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 256, 256, 32)         9248      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 256, 256, 32)         128       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 256, 256, 32)         0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 32)         0         ['activation_3[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 64)         18496     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 128, 128, 64)         256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 128, 128, 64)         0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128, 128, 64)         0         ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 64)         36928     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 128, 128, 64)         256       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 128, 128, 64)         0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 64)           0         ['activation_5[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 64, 64, 128)          512       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 64, 64, 128)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64, 64, 128)          0         ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 128)          147584    ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 64, 64, 128)          512       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 64, 64, 128)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 128)          0         ['activation_7[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 256)          295168    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 32, 32, 256)          1024      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 32, 32, 256)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 32, 32, 256)          0         ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 256)          590080    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 256)          1024      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 32, 32, 256)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 64, 64, 256)          0         ['activation_9[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 64, 64, 384)          0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 64, 64, 128)          442496    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 64, 64, 128)          512       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 64, 64, 128)          0         ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 64, 64, 128)          147584    ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 64, 64, 128)          512       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 128, 128, 128)        0         ['activation_11[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 128, 128, 192)        0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 128, 128, 64)         110656    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 128, 128, 64)         256       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 128, 128, 64)         0         ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 128, 128, 64)         36928     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 128, 128, 64)         256       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 256, 256, 64)         0         ['activation_13[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 256, 256, 96)         0         ['up_sampling2d_2[0][0]',     \n",
            " )                                                                   'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 256, 256, 32)         27680     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 256, 256, 32)         128       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 256, 256, 32)         0         ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 256, 256, 32)         9248      ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 256, 256, 32)         128       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, 512, 512, 32)         0         ['activation_15[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 512, 512, 48)         0         ['up_sampling2d_3[0][0]',     \n",
            " )                                                                   'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 512, 512, 16)         6928      ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 512, 512, 16)         64        ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 512, 512, 16)         0         ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 512, 512, 16)         2320      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 512, 512, 16)         64        ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 512, 512, 1)          17        ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 512, 512, 1)          4         ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 512, 512, 1)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1968229 (7.51 MB)\n",
            "Trainable params: 1965283 (7.50 MB)\n",
            "Non-trainable params: 2946 (11.51 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "16/16 [==============================] - 158s 10s/step - loss: -0.5465 - accuracy: 0.8638 - IoU_coef: 0.5466 - val_loss: -0.2798 - val_accuracy: 0.2530 - val_IoU_coef: 0.2791\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 151s 9s/step - loss: -0.5591 - accuracy: 0.9016 - IoU_coef: 0.5591 - val_loss: -0.5245 - val_accuracy: 0.8962 - val_IoU_coef: 0.5253\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 151s 9s/step - loss: -0.5681 - accuracy: 0.9179 - IoU_coef: 0.5682 - val_loss: -0.5408 - val_accuracy: 0.8962 - val_IoU_coef: 0.5415\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 151s 9s/step - loss: -0.5757 - accuracy: 0.9362 - IoU_coef: 0.5757 - val_loss: -0.5496 - val_accuracy: 0.8962 - val_IoU_coef: 0.5504\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.5801 - accuracy: 0.9367 - IoU_coef: 0.5801 - val_loss: -0.5584 - val_accuracy: 0.8962 - val_IoU_coef: 0.5592\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.5844 - accuracy: 0.9294 - IoU_coef: 0.5844 - val_loss: -0.5662 - val_accuracy: 0.8962 - val_IoU_coef: 0.5670\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.5896 - accuracy: 0.9408 - IoU_coef: 0.5896 - val_loss: -0.5730 - val_accuracy: 0.8962 - val_IoU_coef: 0.5739\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.5932 - accuracy: 0.9262 - IoU_coef: 0.5932 - val_loss: -0.5789 - val_accuracy: 0.8962 - val_IoU_coef: 0.5798\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6004 - accuracy: 0.9463 - IoU_coef: 0.6005 - val_loss: -0.5840 - val_accuracy: 0.8962 - val_IoU_coef: 0.5849\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6053 - accuracy: 0.9475 - IoU_coef: 0.6053 - val_loss: -0.5895 - val_accuracy: 0.8962 - val_IoU_coef: 0.5904\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6097 - accuracy: 0.9419 - IoU_coef: 0.6097 - val_loss: -0.5944 - val_accuracy: 0.8962 - val_IoU_coef: 0.5953\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6161 - accuracy: 0.9535 - IoU_coef: 0.6162 - val_loss: -0.5986 - val_accuracy: 0.8962 - val_IoU_coef: 0.5995\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6219 - accuracy: 0.9578 - IoU_coef: 0.6219 - val_loss: -0.6019 - val_accuracy: 0.8962 - val_IoU_coef: 0.6028\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6265 - accuracy: 0.9572 - IoU_coef: 0.6265 - val_loss: -0.6044 - val_accuracy: 0.8962 - val_IoU_coef: 0.6053\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6310 - accuracy: 0.9579 - IoU_coef: 0.6310 - val_loss: -0.6071 - val_accuracy: 0.8962 - val_IoU_coef: 0.6080\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6354 - accuracy: 0.9571 - IoU_coef: 0.6354 - val_loss: -0.6101 - val_accuracy: 0.8962 - val_IoU_coef: 0.6110\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6406 - accuracy: 0.9602 - IoU_coef: 0.6406 - val_loss: -0.6130 - val_accuracy: 0.8962 - val_IoU_coef: 0.6139\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6447 - accuracy: 0.9601 - IoU_coef: 0.6447 - val_loss: -0.6156 - val_accuracy: 0.8962 - val_IoU_coef: 0.6166\n",
            "Epoch 19/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6489 - accuracy: 0.9577 - IoU_coef: 0.6489 - val_loss: -0.6186 - val_accuracy: 0.8962 - val_IoU_coef: 0.6196\n",
            "Epoch 20/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6538 - accuracy: 0.9616 - IoU_coef: 0.6538 - val_loss: -0.6162 - val_accuracy: 0.8994 - val_IoU_coef: 0.6171\n",
            "Epoch 21/150\n",
            "16/16 [==============================] - 149s 9s/step - loss: -0.6580 - accuracy: 0.9619 - IoU_coef: 0.6580 - val_loss: -0.6148 - val_accuracy: 0.8966 - val_IoU_coef: 0.6158\n",
            "Epoch 22/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6627 - accuracy: 0.9638 - IoU_coef: 0.6627 - val_loss: -0.6149 - val_accuracy: 0.8962 - val_IoU_coef: 0.6158\n",
            "Epoch 23/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6666 - accuracy: 0.9635 - IoU_coef: 0.6667 - val_loss: -0.6108 - val_accuracy: 0.8962 - val_IoU_coef: 0.6117\n",
            "Epoch 24/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6704 - accuracy: 0.9639 - IoU_coef: 0.6704 - val_loss: -0.6033 - val_accuracy: 0.8978 - val_IoU_coef: 0.6042\n",
            "Epoch 25/150\n",
            "16/16 [==============================] - 150s 9s/step - loss: -0.6747 - accuracy: 0.9627 - IoU_coef: 0.6747 - val_loss: -0.6047 - val_accuracy: 0.8966 - val_IoU_coef: 0.6056\n",
            "Epoch 26/150\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9a4c14d27654>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m history = model.fit(x_train, y_train, \n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show imagecodecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGuR91NAzO7D",
        "outputId": "f88e45ea-f709-4e6e-88a3-c7a30762aed7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: imagecodecs\n",
            "Version: 2024.1.1\n",
            "Summary: Image transformation, compression, and decompression codecs\n",
            "Home-page: https://www.cgohlke.com\n",
            "Author: Christoph Gohlke\n",
            "Author-email: cgohlke@cgohlke.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EAq3knEVyGRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzmILqBv9wRI"
      },
      "outputs": [],
      "source": [
        "def res_conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv1 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        conv1 = layers.BatchNormalization(axis=3)(conv1)\n",
        "    conv1 = layers.Activation('relu')(conv1)\n",
        "    conv2 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(conv1)\n",
        "    if batchnorm is True:\n",
        "        conv2 = layers.BatchNormalization(axis=3)(conv2)\n",
        "        conv2 = layers.Activation(\"relu\")(conv2)\n",
        "    if dropout > 0:\n",
        "        conv2 = layers.Dropout(dropout)(conv2)\n",
        "\n",
        "    #skip connection\n",
        "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "    shortcut = layers.Activation(\"relu\")(shortcut)\n",
        "    respath = layers.add([shortcut, conv2])\n",
        "    return respath"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gatingsignal(input, out_size, batchnorm=False):\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batchnorm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "JhtVSg4vG-KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attention unit/block based on soft attention\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), kernel_initializer='he_normal', padding='same')(x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), kernel_initializer='he_normal', padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3), strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]), kernel_initializer='he_normal', padding='same')(phi_g)\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), kernel_initializer='he_normal', padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
        "    upsample_psi = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': shape_x[3]})(upsample_psi)\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), kernel_initializer='he_normal', padding='same')(y)\n",
        "    attenblock = layers.BatchNormalization()(result)\n",
        "    return attenblock\n"
      ],
      "metadata": {
        "id": "2G45__kiHFNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unetmodel(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, dn_4], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, dn_3], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, dn_2], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, dn_1], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ayD9oxiPHF8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Attention U-NET\n",
        "def attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "STHMX7jsHJXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residualunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_conv1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    dn_pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv1)\n",
        "\n",
        "    dn_conv2 = res_conv_block(dn_pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    dn_pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv2)\n",
        "\n",
        "    dn_conv3 = res_conv_block(dn_pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    dn_pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv3)\n",
        "\n",
        "    dn_conv4 = res_conv_block(dn_pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    dn_pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv4)\n",
        "\n",
        "    dn_conv5 = res_conv_block(dn_pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # upsampling layers\n",
        "    up_conv6 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_conv5)\n",
        "    up_conv6 = layers.concatenate([up_conv6, dn_conv4], axis=3)\n",
        "    up_conv6 = res_conv_block(up_conv6, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_conv7 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv6)\n",
        "    up_conv7 = layers.concatenate([up_conv7, dn_conv3], axis=3)\n",
        "    up_conv7 = res_conv_block(up_conv7, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_conv8 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv7)\n",
        "    up_conv8 = layers.concatenate([up_conv8, dn_conv2], axis=3)\n",
        "    up_conv8 = res_conv_block(up_conv8, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_conv9 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv8)\n",
        "    up_conv9 = layers.concatenate([up_conv9, dn_conv1], axis=3)\n",
        "    up_conv9 = res_conv_block(up_conv9, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv9)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "1qcOaZOYHMn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = res_conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = res_conv_block(pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = res_conv_block(pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = res_conv_block(pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = res_conv_block(pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = res_conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = res_conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = res_conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = res_conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "27KssIZCHQXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "\n",
        "\n",
        "def IoU_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def IoU_loss(y_true, y_pred):\n",
        "    return -IoU_coef(y_true, y_pred)\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    return acc\n",
        "\n",
        "def IoU(y_true, y_pred, labels = [0, 1]):\n",
        "   IoU = []\n",
        "   for label in labels:\n",
        "      jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='weighted')\n",
        "      IoU.append(jaccard)\n",
        "   return np.mean(IoU)"
      ],
      "metadata": {
        "id": "sDAjnpk7WtFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7XaBIypIHKF",
        "outputId": "92a3cc4e-a19b-454b-bb76-a62081bd059d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "np.random.seed(0)\n",
        "\n",
        "#CLAHE\n",
        "def clahe_equalized(imgs):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    imgs_equalized = clahe.apply(imgs)\n",
        "    return imgs_equalized\n",
        "\n",
        "path1 = 'drive/My Drive/training/diabetic_retinopathy_input'  # training images directory\n",
        "path2 = 'drive/My Drive/training/diabetic_retinopathy_fovmask'  # training masks directory\n",
        "\n",
        "image_dataset = []\n",
        "mask_dataset = []\n",
        "\n",
        "patch_size = 512\n",
        "\n",
        "for i in range(1, 16):\n",
        "    image_name = f\"{i:02d}_dr.jpg\"\n",
        "    mask_name = f\"{i:02d}_dr_mask.tif\"\n",
        "\n",
        "    # Read image\n",
        "    image = skimage.io.imread(os.path.join(path1, image_name))\n",
        "    image = image[:,:,1]  # selecting green channel\n",
        "    image = clahe_equalized(image)  # applying CLAHE\n",
        "\n",
        "    SIZE_X = (image.shape[1] // patch_size) * patch_size  # getting size multiple of patch size\n",
        "    SIZE_Y = (image.shape[0] // patch_size) * patch_size  # getting size multiple of patch size\n",
        "    image = Image.fromarray(image)\n",
        "    image = image.resize((SIZE_X, SIZE_Y))  # resize image\n",
        "    image = np.array(image)\n",
        "    patches_img = patchify(image, (patch_size, patch_size), step=patch_size)  # create patches(patch_size x patch_size x 1)\n",
        "\n",
        "    for i in range(patches_img.shape[0]):\n",
        "        for j in range(patches_img.shape[1]):\n",
        "            single_patch_img = patches_img[i,j,:,:]\n",
        "            single_patch_img = (single_patch_img.astype('float32')) / 255.\n",
        "            image_dataset.append(single_patch_img)\n",
        "\n",
        "    # Read mask\n",
        "    mask = skimage.io.imread(os.path.join(path2, mask_name))  # Read mask\n",
        "    mask = (mask > 0).astype(np.uint8)  # Convert to binary mask\n",
        "    mask = np.expand_dims(mask, axis=-1)  # Add channel dimension for compatibility\n",
        "    SIZE_X = (mask.shape[1] // patch_size) * patch_size  # getting size multiple of patch size\n",
        "    SIZE_Y = (mask.shape[0] // patch_size) * patch_size  # getting size multiple of patch size\n",
        "    mask = Image.fromarray(mask.squeeze())\n",
        "    mask = mask.resize((SIZE_X, SIZE_Y))  # resize mask\n",
        "    mask = np.array(mask)\n",
        "    patches_mask = patchify(mask, (patch_size, patch_size, 1), step=patch_size)  # create patches(patch_size x patch_size x 1)\n",
        "\n",
        "    # Append mask patches to dataset\n",
        "    for i in range(patches_mask.shape[0]):\n",
        "        for j in range(patches_mask.shape[1]):\n",
        "            single_patch_mask = patches_mask[i,j,:,:]\n",
        "            single_patch_mask = (single_patch_mask.astype('float32'))/255.\n",
        "            mask_dataset.append(single_patch_mask)\n",
        "\n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "image_dataset = np.expand_dims(image_dataset, axis=-1)\n",
        "mask_dataset =  np.expand_dims(mask_dataset, axis=-1)\n"
      ],
      "metadata": {
        "id": "LGeNscnBYSvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "33f379b6-f5c9-4b57-fd10-993f39d8e8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file: '/content/drive/My Drive/training/diabetic_retinopathy_input/01_dr.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-bdf9df34ab8a>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# selecting green channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclahe_equalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# applying CLAHE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mimopen_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legacy_mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimopen_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py\u001b[0m in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_hint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<bytes>\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/drive/My Drive/training/diabetic_retinopathy_input/01_dr.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==0.19.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A5SUQxEFIV4",
        "outputId": "cb677d57-61b6-4858-cf68-7a13739fed4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.19.1\n",
            "  Downloading scikit-learn-0.19.1.tar.gz (9.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scikit-learn\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "Failed to build scikit-learn\n",
            "\u001b[31mERROR: Could not build wheels for scikit-learn, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "IMG_HEIGHT = patch_size\n",
        "IMG_WIDTH = patch_size\n",
        "IMG_CHANNELS = 1\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "model = unetmodel(input_shape)\n",
        "model.compile(optimizer = Adam(learning_rate=1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "#model = residualunet(input_shape)\n",
        "#model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "#model = attentionunet(input_shape)\n",
        "#model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "#model = attention_residualunet(input_shape)\n",
        "#model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "# Check the data size\n",
        "print(image_dataset.shape)\n",
        "print(mask_dataset.shape)\n",
        "\n",
        "if len(image_dataset) == 0 or len(mask_dataset) == 0:\n",
        "    raise ValueError(\"Image or mask dataset is empty. Please check the data loading process.\")\n",
        "\n",
        "# Modify the train_test_split function\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, test_index in kf.split(image_dataset):\n",
        "    x_train, x_test = image_dataset[train_index], image_dataset[test_index]\n",
        "    y_train, y_test = mask_dataset[train_index], mask_dataset[test_index]\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train,\n",
        "          verbose=1,\n",
        "          batch_size=16,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=False,\n",
        "          epochs=150)\n",
        "\n",
        "#training-validation loss curve\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#training-validation accuracy curve\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'y', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#training-validation IoU curve\n",
        "iou_coef = history.history['IoU_coef']\n",
        "val_iou_coef = history.history['val_IoU_coef']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, iou_coef, 'r', label='Training IoU')\n",
        "plt.plot(epochs, val_iou_coef, 'y', label='Validation IoU')\n",
        "plt.title('Training and validation IoU coefficients')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2DaSFj1CWtQ4",
        "outputId": "baf3fafa-61f0-451c-9f8f-9c4332f45121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 512, 512, 16)         160       ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 512, 512, 16)         64        ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_27 (Dropout)        (None, 512, 512, 16)         0         ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 512, 512, 16)         2320      ['dropout_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 512, 512, 16)         64        ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooli  (None, 256, 256, 16)         0         ['activation_58[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 256, 256, 32)         4640      ['max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 256, 256, 32)         128       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)        (None, 256, 256, 32)         0         ['activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 256, 256, 32)         9248      ['dropout_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 256, 256, 32)         128       ['conv2d_60[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooli  (None, 128, 128, 32)         0         ['activation_60[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 128, 128, 64)         18496     ['max_pooling2d_13[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 128, 128, 64)         256       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)        (None, 128, 128, 64)         0         ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 128, 128, 64)         36928     ['dropout_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 128, 128, 64)         256       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooli  (None, 64, 64, 64)           0         ['activation_62[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 64, 64, 128)          73856     ['max_pooling2d_14[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 64, 64, 128)          512       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)        (None, 64, 64, 128)          0         ['activation_63[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 64, 64, 128)          147584    ['dropout_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 64, 64, 128)          512       ['conv2d_64[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooli  (None, 32, 32, 128)          0         ['activation_64[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 32, 32, 256)          295168    ['max_pooling2d_15[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 32, 32, 256)          1024      ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)        (None, 32, 32, 256)          0         ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 32, 32, 256)          590080    ['dropout_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 32, 32, 256)          1024      ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_12 (UpSampli  (None, 64, 64, 256)          0         ['activation_66[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 64, 64, 384)          0         ['up_sampling2d_12[0][0]',    \n",
            " e)                                                                  'activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 64, 64, 128)          442496    ['concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 64, 64, 128)          512       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)        (None, 64, 64, 128)          0         ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 64, 64, 128)          147584    ['dropout_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 64, 64, 128)          512       ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_13 (UpSampli  (None, 128, 128, 128)        0         ['activation_68[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 128, 128, 192)        0         ['up_sampling2d_13[0][0]',    \n",
            " e)                                                                  'activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 128, 128, 64)         110656    ['concatenate_13[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 128, 128, 64)         256       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)        (None, 128, 128, 64)         0         ['activation_69[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 128, 128, 64)         36928     ['dropout_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 128, 128, 64)         256       ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_14 (UpSampli  (None, 256, 256, 64)         0         ['activation_70[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_14[0][0]',    \n",
            " e)                                                                  'activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 256, 256, 32)         27680     ['concatenate_14[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 256, 256, 32)         128       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)        (None, 256, 256, 32)         0         ['activation_71[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 256, 256, 32)         9248      ['dropout_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 256, 256, 32)         128       ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_15 (UpSampli  (None, 512, 512, 32)         0         ['activation_72[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 512, 512, 48)         0         ['up_sampling2d_15[0][0]',    \n",
            " e)                                                                  'activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 512, 512, 16)         6928      ['concatenate_15[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 512, 512, 16)         64        ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)        (None, 512, 512, 16)         0         ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 512, 512, 16)         2320      ['dropout_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 512, 512, 16)         64        ['conv2d_74[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 512, 512, 1)          17        ['activation_74[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 512, 512, 1)          4         ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 512, 512, 1)          0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1968229 (7.51 MB)\n",
            "Trainable params: 1965283 (7.50 MB)\n",
            "Non-trainable params: 2946 (11.51 KB)\n",
            "__________________________________________________________________________________________________\n",
            "(0, 1)\n",
            "(0, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Image or mask dataset is empty. Please check the data loading process.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8d03f08e3e2b>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image or mask dataset is empty. Please check the data loading process.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Modify the train_test_split function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Image or mask dataset is empty. Please check the data loading process."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "NCqvublGcZoX",
        "outputId": "bab24fc8-51aa-4644-dc4e-57bfaf9cd5e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVM3msnlHW_a",
        "outputId": "e520c6b8-912b-4a1c-f2f9-51c19900da2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.25.2)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGebSyyVY0CH",
        "outputId": "3aa26be4-e63a-4f39-ea75-338d3271912d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall imagecodecs -y\n",
        "!pip install imagecodecs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gn3BaY0KPDC",
        "outputId": "4af4eb8a-397d-4314-a5f5-ccdc422d0ecc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping imagecodecs as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting imagecodecs\n",
            "  Downloading imagecodecs-2024.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagecodecs) (1.25.2)\n",
            "Installing collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2024.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tifffile\n",
        "!pip install tifffile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "23mbIM3-znom",
        "outputId": "3c23e925-c05d-4a4c-c0f2-09b9ae6f05f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tifffile 2024.5.3\n",
            "Uninstalling tifffile-2024.5.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/lsm2bin\n",
            "    /usr/local/bin/tiff2fsspec\n",
            "    /usr/local/bin/tiffcomment\n",
            "    /usr/local/bin/tifffile\n",
            "    /usr/local/lib/python3.10/dist-packages/tifffile-2024.5.3.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tifffile/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tifffile-2024.5.3\n",
            "Collecting tifffile\n",
            "  Downloading tifffile-2024.5.10-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tifffile) (1.25.2)\n",
            "Installing collected packages: tifffile\n",
            "Successfully installed tifffile-2024.5.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tifffile"
                ]
              },
              "id": "929d22d5ba8748d1aa3d4f8b91fdd822"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}